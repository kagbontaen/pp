{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](https://www.iberdrola.com/wcorp/gc/prod/pt_BR/comunicacion/machine_learning_mult_1_res/machine_learning_746x419.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Table of Contents"]},{"cell_type":"markdown","metadata":{},"source":["1. [Introduction](#1.-Introduction)\n","\n","2. [Base Libraries](#2.-Base-Libraries)\n","\n","3. [Data Preprocessing](#3.-Data-Preprocessing)\n","\n","4. [Feature Selection](#4.-Feature-Selection)\n","\n","5. [Conclusions](#5.-Conclusions)\n","\n","6. [References](#6.-References)"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Introduction"]},{"cell_type":"markdown","metadata":{},"source":["During my studies, I tried to find a good example (or notebook) about RReliefF (Relief for Regression). Unfortunately, I couldn't find anything that suited my needs, as there were many examples for Classification, and almost none for Regression. So, I decided to collaborate with the Kaggle community and create an example of how to use RReliefF. To achieve this goal, I used the sklearn_relief library (https://gitlab.com/moongoal/sklearn-relief)\n","\n","Relief is an algorithm developed by Kira and Rendell in 1992 that takes a filter-method approach to feature selection that is notably sensitive to feature interactions. It was originally designed for application to binary classification problems with discrete or numerical features. Relief calculates a feature score for each feature which can then be applied to rank and select top scoring features for feature selection. \n","\n","Robnik-Šikonja and Kononenko propose further updates to ReliefF, making it appropriate for regression (RReliefF, the focus of this notebook)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Base Libraries"]},{"cell_type":"markdown","metadata":{},"source":["First, the basic libraries are imported: **pandas**, **matplotlib**, **seaborn**, **numpy** to Dataframes, Graphs and numeric operations; **MinMaxScaler** to normalize our data between 0 and 1, **train_test_split** to help split the dataset (usually 70% training/ 30% testing). We'll use **power_transform** to make data more Gaussian-like, **RandomForestRegressor** to wrap the RReliefF algorithm on the second example, and **sklearn_relief** for obvious reasons"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-09-09T05:55:06.719958Z","iopub.status.busy":"2023-09-09T05:55:06.719492Z","iopub.status.idle":"2023-09-09T05:55:14.651715Z","shell.execute_reply":"2023-09-09T05:55:14.650638Z","shell.execute_reply.started":"2023-09-09T05:55:06.719925Z"},"trusted":true},"outputs":[],"source":["#%pip install sklearn_relief"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-09-09T05:55:14.653672Z","iopub.status.busy":"2023-09-09T05:55:14.653375Z","iopub.status.idle":"2023-09-09T05:55:16.052095Z","shell.execute_reply":"2023-09-09T05:55:16.050838Z","shell.execute_reply.started":"2023-09-09T05:55:14.653641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[".\\kaggle\\input\\Amprion.csv\n","yes {'.\\\\kaggle\\\\input\\\\Amprion.csv'}\n"]},{"ename":"TypeError","evalue":"'str' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[34], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m df_amp\u001b[39m=\u001b[39m{os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dirname, filename)}\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myes \u001b[39m\u001b[39m{\u001b[39;00mdf_amp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m df_amp\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mkaggle\u001b[39m\u001b[39m\\\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAmprion.csv\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1795\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         new_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index)\n\u001b[1;32m-> 1795\u001b[0m     df \u001b[39m=\u001b[39m DataFrame(col_dict, columns\u001b[39m=\u001b[39mcolumns, index\u001b[39m=\u001b[39mindex)\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_rows\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqueeze \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, typ\u001b[39m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:443\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[1;32m--> 443\u001b[0m     arrays \u001b[39m=\u001b[39m Series(data, index\u001b[39m=\u001b[39mcolumns, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m    444\u001b[0m     missing \u001b[39m=\u001b[39m arrays\u001b[39m.\u001b[39misna()\n\u001b[0;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# GH10856\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# raise ValueError if only scalars in dict\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:399\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[39m# uncomment the line below when removing the FutureWarning\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[39m# dtype = np.dtype(object)\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     data \u001b[39m=\u001b[39m {}\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7331\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7329\u001b[0m         \u001b[39mreturn\u001b[39;00m MultiIndex\u001b[39m.\u001b[39mfrom_arrays(index_like)\n\u001b[0;32m   7330\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 7331\u001b[0m         \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   7332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7333\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:715\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[39mConstructor that uses the 1.0.x behavior inferring numeric dtypes\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[39mfor ndarray[object] inputs.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m--> 715\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m    716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    718\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[0;32m    719\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"]}],"source":["# Base Libraries\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","# Transformation\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import power_transform\n","from sklearn.pipeline import Pipeline\n","# Feature Selection\n","import sklearn_relief as sr\n","# Models\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","import warnings\n","import os\n","warnings.filterwarnings=('ignore')\n","for dirname, _, filenames in os.walk('.\\kaggle\\input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        if 'Amprion' in filename:\n","            df_amp={os.path.join(dirname, filename)}\n","            print(f\"yes {df_amp}\")\n","            df_amp=pd.read_csv('.\\kaggle\\input\\Amprion.csv') #df_amp = pd.read_csv(os.path.join(dirname, filename)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["The main focus of this kernel is the RReliefF algorithm, but let's spend some time on the data preprocessing, to make our job easier."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-09-09T05:55:16.053710Z","iopub.status.busy":"2023-09-09T05:55:16.053351Z","iopub.status.idle":"2023-09-09T05:55:17.112105Z","shell.execute_reply":"2023-09-09T05:55:17.111063Z","shell.execute_reply.started":"2023-09-09T05:55:16.053676Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[".\\kaggle\\input\\Amprion.csv\n"]},{"ename":"TypeError","evalue":"'str' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m filenames:\n\u001b[0;32m      3\u001b[0m         \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dirname, filename))\n\u001b[1;32m----> 4\u001b[0m         df_amp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dirname, filename))\n\u001b[0;32m      5\u001b[0m dates \u001b[39m=\u001b[39m df_amp[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m df_amp \u001b[39m=\u001b[39m df_amp\u001b[39m.\u001b[39mT\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1795\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         new_rows \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index)\n\u001b[1;32m-> 1795\u001b[0m     df \u001b[39m=\u001b[39m DataFrame(col_dict, columns\u001b[39m=\u001b[39mcolumns, index\u001b[39m=\u001b[39mindex)\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_rows\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqueeze \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, typ\u001b[39m=\u001b[39mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:443\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[1;32m--> 443\u001b[0m     arrays \u001b[39m=\u001b[39m Series(data, index\u001b[39m=\u001b[39mcolumns, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m    444\u001b[0m     missing \u001b[39m=\u001b[39m arrays\u001b[39m.\u001b[39misna()\n\u001b[0;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# GH10856\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# raise ValueError if only scalars in dict\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:399\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[39m# uncomment the line below when removing the FutureWarning\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[39m# dtype = np.dtype(object)\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     data \u001b[39m=\u001b[39m {}\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7331\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7329\u001b[0m         \u001b[39mreturn\u001b[39;00m MultiIndex\u001b[39m.\u001b[39mfrom_arrays(index_like)\n\u001b[0;32m   7330\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 7331\u001b[0m         \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   7332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7333\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:715\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[39mConstructor that uses the 1.0.x behavior inferring numeric dtypes\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[39mfor ndarray[object] inputs.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m--> 715\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m    716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    718\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[0;32m    719\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"]}],"source":["\n","dates = df_amp['Date']\n","df_amp = df_amp.T\n","df_amp = df_amp[1:]\n","df_amp.columns = [dates]\n","\n","df_amp.reset_index(drop=True, inplace=True)\n","\n","scaler = MinMaxScaler()\n","\n","df_amp = power_transform(df_amp, method='yeo-johnson')\n","df_amp = scaler.fit_transform(df_amp)\n","\n","X = df_amp[:,0:396]\n","y = df_amp[:,396]\n","\n","# (optional) plot train & test\n","fig, ax=plt.subplots(1,2,figsize=(30, 6))\n","sns.distplot(X, ax=ax[0])\n","sns.distplot(y, ax=ax[1])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, the data will be imported, transposed so that we can use the days of the year as parameters, transformed using the **yeo-johnson** method and presented to see if they are resembling a Gaussian pattern."]},{"cell_type":"markdown","metadata":{},"source":["# 4. Feature Selection"]},{"cell_type":"markdown","metadata":{},"source":["A large variety of feature selection methodologies have been proposed and research continues to support the claim that there is no universal “best” method for all tasks. In this section, the RReliefF is described in Filter and Wrapped Methods"]},{"cell_type":"markdown","metadata":{},"source":["## 4.1 Filter Method"]},{"cell_type":"markdown","metadata":{},"source":["This method uses a ‘proxy measure’ calculated from the general characteristics of the training data to score features or feature subsets as a processing step prior to modeling. Filters are generally **much faster and function independently** of the induction algorithm, meaning that selected features can then be passed to any modeling algorithm. Filter methods can be roughly classified further by the filtering measures they employ, i.e. information, distance, dependence, consistency, similarity, and statistical measures."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n","r = sr.RReliefF(n_features = 20)\n","print(r.fit_transform(X_train,y_train))"]},{"cell_type":"markdown","metadata":{},"source":["Accordingly to the original implementation, a RReliefF used in filter method will rank all the features, based on importance. "]},{"cell_type":"markdown","metadata":{},"source":["## 4.2 Wrapper Method"]},{"cell_type":"markdown","metadata":{},"source":["The best definition to this method: It **employs any stand-alone modeling algorithm to train a predictive model using a candidate feature subset**. The testing performance on a hold-out set is typically used to score the feature set. Alternatively in a modeling algorithm like a random forest (that I used in this example) , estimated feature importance scores can be applied to select a feature subset. In any wrapper method, a new model must be trained to test any subsequent feature subset, therefore wrapper methods are typically iterative and computationally intensive, but **can identify the best performing features set for that specific modeling algorithm**. Each iteration of the wrapper, the feature subset is generated based on the selected search strategy, e.g. forward or backward selection or a heuristic feature subset selection."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2023-09-09T05:55:32.290998Z","iopub.status.busy":"2023-09-09T05:55:32.290706Z"},"trusted":true},"outputs":[],"source":["nof_list=np.arange(1,5)#20)            \n","high_score=0\n","nof=0           \n","score_list =[]\n","for n in range(len(nof_list)):\n","    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n","    fs = sr.RReliefF(n_features = nof_list[n])\n","    relief = Pipeline([('fs', fs), ('m', RandomForestRegressor())])\n","    relief.fit(X_train,y_train)\n","    score = relief.score(X_test,y_test)\n","    score_list.append(score)\n","    print(f'NOF: {nof_list[n]}, Score: {score}')\n","    if(score > high_score):\n","        high_score = score\n","        nof = nof_list[n]\n","\n","print (print(f'High Score: NOF: {nof}, Score: {high_score}'))"]},{"cell_type":"markdown","metadata":{},"source":["In this case, I wrapped the RReliefF algorithm in an Random Forest Regressor pipeline. The RF hyperparametrization wasn't done, but of course it can be used to improve even more the accuracy of this model. Here, the model is tested with n between 1 and 20 features, giving us the best values for this dataset."]},{"cell_type":"markdown","metadata":{},"source":["## 5. Conclusions"]},{"cell_type":"markdown","metadata":{},"source":["Accordinly to the original paper, RReliefF can **discover strong dependencies between attributes**, while in domains without such dependencies it **performs the same as the mean squared error**. It is also robust and noise tolerant. Its intrinsic contextual nature allows it to recognize contextual attributes. From paper's original experimental results, it's concluded that learning regression trees with RReliefF is promising especially in combination with linear models in the leaves of the tree."]},{"cell_type":"markdown","metadata":{},"source":["## 6. References"]},{"cell_type":"markdown","metadata":{},"source":["[1] Bolon-Canedo, V., Sanchez-Marono, N., Alonso-Betanzos, A., 2013. A Review of Feature Selection\n","Methods on Synthetic data. Knowledge and Information Systems 34 (3), 483–519.\n","\n","[2] Dash, M., Liu, H., 1997. Feature Selection for Classification. Intelligent Data Analysis 1 (1-4), 131–156.\n","\n","[3] Guyon, I., Elisseeff, A., 2003. An Introduction to Variable and Feature Selection. Journal of Machine\n","Learning Research 3 (Mar), 1157–1182.\n","\n","[4] Holland, J. H., 1992. Adaptation in Natural and Artificial Systems. 1975. Ann Arbor, MI: University\n","of Michigan Press.\n","\n","[5] Jovic, A., Brkic, K., Bogunovic, N., 2015. A Review of Feature Selection Methods with Applications. In: Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2015 38th\n","International Convention on. IEEE, pp. 1200–1205.\n","\n","[6] Kira, Kenji and Rendell, Larry (1992). The Feature Selection Problem: Traditional Methods and a New Algorithm. AAAI-92 Proceedings.\n","\n","[7] Kira, Kenji and Rendell, Larry (1992) A Practical Approach to Feature Selection, Proceedings of the Ninth International Workshop on Machine Learning, p249-256\n","\n","[8] Kittler, J., 1978. Feature set Search algorithms. Pattern Recognition and Signal Processing.\n","\n","[9] Langley, P., 1994. Selection of Relevant Features in Machine Learning. In: Proceedings of the AAAI Fall Symposium on Relevance. Vol. 184. pp. 245–271\n","\n","[10] Menze, B. H., Kelm, B. M., Masuch, R., Himmelreich, U., Bachert, P., Petrich, W., Hamprecht, F. A., 2009. A Comparison of Random Forest and its Gini Importance with Standard Chemometric Methods for the Feature Selection and Classification of Spectral Data. BMC Bioinformatics 10 (1), 213\n","\n","[11] Ni, W., 2012. A Review and Comparative Study on Univariate Feature Selection Techniques. Ph.D. thesis, University of Cincinnati.\n","\n","[12] Robnik-Šikonja, Marko, and Kononenko, Igor (1997). An Adaptation of Relief for Attribute Estimation in Regression. Machine Learning: Proceedings of the Fourteenth International Conference (ICML’97) (p296-304)\n","\n","[13] Van Laarhoven, P. J., Aarts, E. H., 1987. Simulated Annealing. In: Simulated Annealing: Theory and\n","Applications. Springer, pp. 7–15."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
